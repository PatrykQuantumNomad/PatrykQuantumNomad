---
phase: 56-infrastructure-foundation
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/lib/eda/math/statistics.ts
  - tests/eda/statistics.test.ts
autonomous: true
requirements:
  - INFRA-01

must_haves:
  truths:
    - "runsTest(normalRandom) returns Z statistic matching NIST value -1.0744"
    - "bartlettTest(normalRandom, 10) returns T statistic matching NIST value 2.3737"
    - "leveneTest(cryothermometry, 10) returns W statistic matching NIST value 1.43"
    - "andersonDarlingNormal(normalRandom) returns A^2 statistic matching NIST value 1.0612"
    - "grubbsTest(normalRandom) returns G statistic matching NIST value 3.3681"
    - "ppccNormal(normalRandom) returns correlation coefficient matching NIST value 0.996"
    - "locationTest(normalRandom) returns t-statistic matching NIST value -0.1251"
  artifacts:
    - path: "src/lib/eda/math/statistics.ts"
      provides: "7 hypothesis test functions + 6 helper functions"
      exports: ["runsTest", "leveneTest", "bartlettTest", "andersonDarlingNormal", "grubbsTest", "ppccNormal", "locationTest", "normalCDF", "chiSquareQuantile", "tQuantile", "fQuantile", "pearsonCorrelation", "sortedMedian"]
    - path: "tests/eda/statistics.test.ts"
      provides: "NIST validation tests for all hypothesis test functions"
      min_lines: 80
  key_links:
    - from: "tests/eda/statistics.test.ts"
      to: "src/lib/eda/math/statistics.ts"
      via: "import of test functions"
      pattern: "import.*from.*statistics"
    - from: "src/lib/eda/math/statistics.ts"
      to: "NIST validation values"
      via: "test assertions matching known NIST dataset results"
      pattern: "toBeCloseTo"
---

<objective>
Implement 7 hypothesis test functions and 6 helper functions in the statistics library using TDD against known NIST validation values.

Purpose: All subsequent case study phases (57-62) need computed hypothesis test results (runs test, Levene, Bartlett, Anderson-Darling, Grubbs, PPCC, location regression t-test) to display in their quantitative results sections. Without these functions, every content phase would be blocked.

Output: Extended `statistics.ts` with 13 new exported functions, validated against NIST case study datasets.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/56-infrastructure-foundation/56-RESEARCH.md

@src/lib/eda/math/statistics.ts
@src/data/eda/datasets.ts
</context>

<feature>
  <name>Hypothesis Test Functions for EDA Statistics Library</name>
  <files>src/lib/eda/math/statistics.ts, tests/eda/statistics.test.ts</files>
  <behavior>
    Each function takes a data array (number[]) and returns a structured result object containing at minimum: statistic, criticalValue, and reject (boolean).

    Validation cases (from NIST case study datasets):

    **Helper functions (no direct test validation, but used by test functions):**
    - normalCDF(z: number): number -- Standard normal CDF
    - chiSquareQuantile(p: number, df: number): number -- Chi-square inverse CDF (Wilson-Hilferty approximation)
    - tQuantile(p: number, df: number): number -- Student's t inverse CDF (Hill's Algorithm 396)
    - fQuantile(p: number, df1: number, df2: number): number -- F-distribution inverse CDF
    - pearsonCorrelation(x: number[], y: number[]): number -- Pearson r correlation
    - sortedMedian(data: number[]): number -- Median of sorted array

    **Test functions with NIST validation values:**

    runsTest(normalRandom) -> { statistic: -1.0744, criticalValue: 1.96, reject: false }
    runsTest(cryothermometry) -> { statistic: -13.4162, reject: true }
    runsTest(heatFlowMeter) -> { statistic: -3.2306, reject: true }
    runsTest(filterTransmittance) -> { statistic: -5.3246, reject: true }

    bartlettTest(normalRandom, k) -> { statistic: 2.3737, reject: false }
    bartlettTest(heatFlowMeter, k) -> { statistic: 3.147, reject: false }

    leveneTest(cryothermometry, k) -> { statistic: 1.43, reject: false }
    leveneTest(filterTransmittance, k) -> { statistic: 0.971, reject: false }

    andersonDarlingNormal(normalRandom) -> { statistic: 1.0612, reject: true }
    andersonDarlingNormal(cryothermometry) -> { statistic: 16.858, reject: true }
    andersonDarlingNormal(heatFlowMeter) -> { statistic: 0.129, reject: false }

    grubbsTest(normalRandom) -> { statistic: 3.3681, reject: false }
    grubbsTest(cryothermometry) -> { statistic: 2.729, reject: false }
    grubbsTest(heatFlowMeter) -> { statistic: 2.918673, reject: false }

    ppccNormal(normalRandom) -> { statistic: 0.996, reject: false }
    ppccNormal(cryothermometry) -> { statistic: 0.975, reject: true }
    ppccNormal(heatFlowMeter) -> { statistic: 0.996, reject: false }

    locationTest(normalRandom) -> { tStatistic: -0.1251, reject: false }
    locationTest(cryothermometry) -> { tStatistic: 4.445, reject: true }
    locationTest(heatFlowMeter) -> { tStatistic: -1.960, reject: false }
    locationTest(filterTransmittance) -> { tStatistic: 5.582, reject: true }
  </behavior>
  <implementation>
    **Implementation order (helpers first, then tests that use them):**

    1. **Helper functions** (add to statistics.ts before test functions):
       - `normalCDF(z)`: Use the complementary error function relationship: `Phi(z) = 0.5 * (1 + erf(z / sqrt(2)))`. Implement erf using Horner form of the Abramowitz & Stegun rational approximation (max error 1.5e-7).
       - `sortedMedian(data)`: Simple median of pre-sorted array. For even n, average of two middle values.
       - `pearsonCorrelation(x, y)`: Standard formula: r = sum((xi-mx)(yi-my)) / sqrt(sum((xi-mx)^2) * sum((yi-my)^2)). Reuse `mean()`.
       - `chiSquareQuantile(p, df)`: Wilson-Hilferty approximation: x = df * (1 - 2/(9*df) + normalQuantile(p) * sqrt(2/(9*df)))^3. Accurate to ~3-4 decimals for df >= 3.
       - `tQuantile(p, df)`: For df >= 3, use the Abramowitz & Stegun approximation via normal approximation with correction terms. For large df (>= 120), fall back to normalQuantile(p). For small df, use a more precise rational approximation.
       - `fQuantile(p, df1, df2)`: Derive from beta incomplete function approximation, or use the relationship F = (chi2_1/df1) / (chi2_2/df2).

    2. **Hypothesis test functions** (add below helpers in statistics.ts):
       - `runsTest(data)`: Count runs above/below median. Z = (R - E[R]) / sd(R). See NIST Section 1.3.5.13. Handle even-n median ties by assigning to "below" group.
       - `bartlettTest(data, k)`: Split data into k equal groups, compute pooled variance, Bartlett T statistic with correction factor. Chi-square critical value at alpha=0.05. See NIST Section 1.3.5.7.
       - `leveneTest(data, k)`: Split into k groups, compute median-based absolute deviations, one-way ANOVA on deviations. F critical value at alpha=0.05. See NIST Section 1.3.5.10.
       - `andersonDarlingNormal(data)`: Sort data, compute standard normal CDF values, compute A^2 = -N - S. Clamp CDF to [1e-10, 1-1e-10] to avoid log(0). Use critical value 0.787 per NIST convention. See NIST Section 1.3.5.14.
       - `grubbsTest(data)`: G = max|Yi - Ybar| / s. Critical value from t-distribution formula. See NIST Section 1.3.5.17.1.
       - `ppccNormal(data)`: Sort data, compute Filliben plotting positions, correlation with normal order statistics. Use hardcoded critical value lookup table for common sample sizes. See Filliben (1975).
       - `locationTest(data)`: Regress data on run order (1..N), compute slope t-statistic. Extends existing `linearRegression()`. See NIST case study quantitative sections.

    **Critical implementation details:**
    - Group size k for Bartlett/Levene: The case studies use k values that produce roughly equal groups. The function accepts k as a parameter; the MDX caller chooses k. Common values: k=10 for n=500, k=10 for n=700, k=10 for n=195, k=10 for n=50.
    - Anderson-Darling critical value: Use 0.787 (NIST convention for normality test at alpha=0.05), NOT the Stephens adjustment formula. The case studies consistently compare raw A^2 against 0.787.
    - PPCC critical values: Hardcode a lookup table keyed by sample size: { 50: 0.978, 100: 0.987, 195: 0.987, 200: 0.992, 480: 0.996, 500: 0.997, 700: 0.987, 1000: 0.998 }. For sizes not in the table, interpolate linearly between nearest entries.
    - All functions must be pure (no side effects, no imports beyond other functions in the same file).
    - Follow existing export pattern: named exports at function declaration.
    - Use existing `mean()`, `standardDeviation()`, `linearRegression()`, `normalQuantile()` functions already in statistics.ts.
  </implementation>
</feature>

<verification>
Run the test suite and verify all NIST validation values match:
```bash
npx vitest run tests/eda/statistics.test.ts
```

Also verify the existing Astro build still passes (statistics.ts is imported by SVG generators):
```bash
npx astro check 2>&1 | tail -5
```
</verification>

<success_criteria>
- All 7 hypothesis test functions exported from statistics.ts
- All 6 helper functions exported from statistics.ts
- Test file validates against at least 20 NIST dataset values (4 datasets x 5+ tests each)
- All test assertions pass with toBeCloseTo tolerance appropriate for each statistic
- `npx astro check` reports 0 errors (no regressions in existing code)
</success_criteria>

<output>
After completion, create `.planning/phases/56-infrastructure-foundation/56-01-SUMMARY.md`
</output>
